{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install opensearch-py pyspark matplotlib scikit-learn seaborn pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'boto3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/robertc/Git/pfun-cma-model/pfun_cma_model/embed/embed/nodebooks/kmeans-on-embeddings.ipynb Cell 3\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/robertc/Git/pfun-cma-model/pfun_cma_model/embed/embed/nodebooks/kmeans-on-embeddings.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mif\u001b[39;00m rootpath \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m sys\u001b[39m.\u001b[39mpath:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/robertc/Git/pfun-cma-model/pfun_cma_model/embed/embed/nodebooks/kmeans-on-embeddings.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39minsert(\u001b[39m0\u001b[39m, rootpath)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/robertc/Git/pfun-cma-model/pfun_cma_model/embed/embed/nodebooks/kmeans-on-embeddings.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpfun_cma_model\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39membed\u001b[39;00m \u001b[39mimport\u001b[39;00m EmbedClient, run_embedder\n",
      "File \u001b[0;32m~/Git/pfun-cma-model/pfun_cma_model/embed/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrunpy\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mglobals\u001b[39m()\u001b[39m.\u001b[39mupdate(runpy\u001b[39m.\u001b[39;49mrun_path(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mabspath(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mdirname(\u001b[39m__file__\u001b[39;49m)), \u001b[39m'\u001b[39;49m\u001b[39membed/embed.py\u001b[39;49m\u001b[39m'\u001b[39;49m)))\n",
      "File \u001b[0;32m~/Git/pfun-cma-model/.conda/lib/python3.10/runpy.py:289\u001b[0m, in \u001b[0;36mrun_path\u001b[0;34m(path_name, init_globals, run_name)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(importer, \u001b[39mtype\u001b[39m(\u001b[39mNone\u001b[39;00m)) \u001b[39mor\u001b[39;00m is_NullImporter:\n\u001b[1;32m    286\u001b[0m     \u001b[39m# Not a valid sys.path entry, so run the code directly\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39m# execfile() doesn't help as we want to allow compiled files\u001b[39;00m\n\u001b[1;32m    288\u001b[0m     code, fname \u001b[39m=\u001b[39m _get_code_from_file(run_name, path_name)\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m _run_module_code(code, init_globals, run_name,\n\u001b[1;32m    290\u001b[0m                             pkg_name\u001b[39m=\u001b[39;49mpkg_name, script_name\u001b[39m=\u001b[39;49mfname)\n\u001b[1;32m    291\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    292\u001b[0m     \u001b[39m# Finder is defined for path, so add it to\u001b[39;00m\n\u001b[1;32m    293\u001b[0m     \u001b[39m# the start of sys.path\u001b[39;00m\n\u001b[1;32m    294\u001b[0m     sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39minsert(\u001b[39m0\u001b[39m, path_name)\n",
      "File \u001b[0;32m~/Git/pfun-cma-model/.conda/lib/python3.10/runpy.py:96\u001b[0m, in \u001b[0;36m_run_module_code\u001b[0;34m(code, init_globals, mod_name, mod_spec, pkg_name, script_name)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39mwith\u001b[39;00m _TempModule(mod_name) \u001b[39mas\u001b[39;00m temp_module, _ModifiedArgv0(fname):\n\u001b[1;32m     95\u001b[0m     mod_globals \u001b[39m=\u001b[39m temp_module\u001b[39m.\u001b[39mmodule\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m\n\u001b[0;32m---> 96\u001b[0m     _run_code(code, mod_globals, init_globals,\n\u001b[1;32m     97\u001b[0m               mod_name, mod_spec, pkg_name, script_name)\n\u001b[1;32m     98\u001b[0m \u001b[39m# Copy the globals of the temporary module, as they\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39m# may be cleared when the temporary module goes away\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[39mreturn\u001b[39;00m mod_globals\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/Git/pfun-cma-model/.conda/lib/python3.10/runpy.py:86\u001b[0m, in \u001b[0;36m_run_code\u001b[0;34m(code, run_globals, init_globals, mod_name, mod_spec, pkg_name, script_name)\u001b[0m\n\u001b[1;32m     78\u001b[0m         pkg_name \u001b[39m=\u001b[39m mod_spec\u001b[39m.\u001b[39mparent\n\u001b[1;32m     79\u001b[0m run_globals\u001b[39m.\u001b[39mupdate(\u001b[39m__name__\u001b[39m \u001b[39m=\u001b[39m mod_name,\n\u001b[1;32m     80\u001b[0m                    \u001b[39m__file__\u001b[39m \u001b[39m=\u001b[39m fname,\n\u001b[1;32m     81\u001b[0m                    __cached__ \u001b[39m=\u001b[39m cached,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m                    __package__ \u001b[39m=\u001b[39m pkg_name,\n\u001b[1;32m     85\u001b[0m                    __spec__ \u001b[39m=\u001b[39m mod_spec)\n\u001b[0;32m---> 86\u001b[0m exec(code, run_globals)\n\u001b[1;32m     87\u001b[0m \u001b[39mreturn\u001b[39;00m run_globals\n",
      "File \u001b[0;32m~/Git/pfun-cma-model/pfun_cma_model/embed/embed/embed.py:24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpfun_cma_model\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mruntime\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchalicelib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcma_model_params\u001b[39;00m \u001b[39mimport\u001b[39;00m CMAModelParams\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpfun_cma_model\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mruntime\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchalicelib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcma_sleepwake\u001b[39;00m \u001b[39mimport\u001b[39;00m CMASleepWakeModel\n\u001b[0;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpfun_cma_model\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msecrets\u001b[39;00m \u001b[39mimport\u001b[39;00m get_secret_func \u001b[39mas\u001b[39;00m get_secret\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpfun_cma_model\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mruntime\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchalicelib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcma_model_params\u001b[39;00m \u001b[39mimport\u001b[39;00m Bounds\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpfun_cma_model\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mruntime\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchalicelib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     27\u001b[0m     downsample_data,\n\u001b[1;32m     28\u001b[0m     interp_missing_data,\n\u001b[1;32m     29\u001b[0m )\n",
      "File \u001b[0;32m~/Git/pfun-cma-model/pfun_cma_model/secrets.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Use this code snippet in your app.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# If you need more information about configurations\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# or implementing the sample code, visit the AWS docs:\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# https://aws.amazon.com/developer/language/python/\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbotocore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m ClientError, ProfileNotFound\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpfun_cma_model\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msessions\u001b[39;00m \u001b[39mimport\u001b[39;00m PFunCMASession\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m AnyStr\n",
      "File \u001b[0;32m~/Git/pfun-cma-model/pfun_cma_model/sessions.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     Optional,\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbotocore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m Config \u001b[39mas\u001b[39;00m ConfigCore\n\u001b[0;32m----> 5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mboto3\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbotocore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m ClientError\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mthreading\u001b[39;00m \u001b[39mimport\u001b[39;00m Lock\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'boto3'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "rootpath = os.path.abspath(\"/home/robertc/Git/pfun-cma-model\")\n",
    "if rootpath not in sys.path:\n",
    "    sys.path.insert(0, rootpath)\n",
    "from pfun_cma_model.embed import EmbedClient, run_embedder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the embedder -> embeddings -> Opensearch domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_embedder(grid_params=dict(num=8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize opensearch client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osearc = EmbedClient(require_ssh_tunnel=False).opensearch_client\n",
    "res = osearc.search(\n",
    "    index=\"embeddings\", body={\"size\": 10, \"_source\": \"embedding\"}, scroll=\"2m\"\n",
    ")\n",
    "scroll_id = res[\"_scroll_id\"]\n",
    "scroll_size = res[\"hits\"][\"total\"][\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "# .config(\"spark.jars\", os.path.join(rootpath, \"pfun_cma_model/embed/pyspark_jars/opensearch-spark-30_2.13-1.0.1.jar\"))\n",
    "spark = SparkSession.builder \\\n",
    "    .config(\"spark.cores.max\", \"8\") \\\n",
    "    .config(\"spark.kubernetes.container.image\", \"docker.io/bitnami/spark:3.5.0-debian-11-r0\") \\\n",
    "    .config(\"spark.executor.instances\", \"4\") \\\n",
    ".config(\"spark.jars\", os.path.join(rootpath, \"pfun_cma_model/embed/pyspark_jars/elasticsearch-spark-20_2.11-8.10.2.jar\")) \\\n",
    "    .appName(\"pfun-cma-model-embed\") \\\n",
    "    .getOrCreate()\n",
    "spark.conf.set('spark.sql.shuffle.partitions', int(16 * 2.5))\n",
    "spark.conf.set('spark.default.parallelism', 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Data from OpenSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = [(d[\"_source\"][\"embedding\"][0][\"embedding\"],) for d in res[\"hits\"][\"hits\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataFromOSWithSpark(index: str = \"embeddings\", sample_fraction: float | None = 0.1):\n",
    "    #: Get data from opensearch (with spark)\n",
    "    df = (\n",
    "        spark.read.format(\"org.elasticsearch.spark.sql\")\n",
    "        .option(\"es.port\", \"9201\")\n",
    "        .option(\"es.net.ssl\", \"false\")\n",
    "        .option(\"es.nodes\", \"192.168.1.64\")\n",
    "        .load(f\"{index}/float\")\n",
    "    )\n",
    "    if sample_fraction is not None:\n",
    "        # Create random sample of 10% of the data\n",
    "        df_sample = df.sample(False, sample_fraction)\n",
    "        return df_sample\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "\n",
    "# df = getDataFromOSWithSpark(sample_fraction=0.1)\n",
    "# df.persist()\n",
    "# df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import ArrayType, DoubleType, StructType, StructField\n",
    "\n",
    "schema = StructType([StructField(\"list_features\", ArrayType(DoubleType()))])\n",
    "df = spark.createDataFrame(embeddings, schema=schema)\n",
    "\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "# UDF to convert array into vector\n",
    "vector_udf = udf(lambda l: Vectors.dense(l), VectorUDT())\n",
    "df = df.withColumn(\"features\", vector_udf(\"list_features\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(\"features\")\n",
    "df.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "kmeans = KMeans(k=8, seed=23)\n",
    "model = kmeans.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "df_pandas = pd.DataFrame(\n",
    "    model.transform(df)\n",
    "    .rdd.map(lambda r: (float(r.features[0]), float(r.features[1]), int(r.prediction)))\n",
    "    .collect(),\n",
    "    columns=[\"x\", \"y\", \"cluster\"],\n",
    ")\n",
    "df_pandas[\"x\"], df_pandas[\"y\"] = zip(*pca.fit_transform(df_pandas[[\"x\", \"y\"]]))\n",
    "plt.rc(\"figure\", figsize=(10, 8))\n",
    "sns.scatterplot(x=\"x\", y=\"y\", hue=\"cluster\", data=df_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_query_vector():\n",
    "    from pfun_cma_model.embed import encode\n",
    "    from pfun_cma_model.runtime.chalicelib.engine.cma_sleepwake import CMASleepWakeModel\n",
    "    cma = CMASleepWakeModel()\n",
    "    raw_text = cma.run().to_json()\n",
    "    queryVector = encode(raw_text)[0].tolist()\n",
    "    return queryVector\n",
    "\n",
    "\n",
    "def get_sample_query_vector():\n",
    "    sample = osearc.search(\n",
    "        index=\"embeddings\", body={\"size\": 1, \"_source\": \"embedding\"}, scroll=\"2m\"\n",
    "    )\n",
    "    queryVector = sample['hits']['hits'][0]['_source']['embedding'][0]['embedding']\n",
    "    return queryVector\n",
    "\n",
    "\n",
    "queryVector = get_sample_query_vector()\n",
    "\n",
    "query = {\n",
    "    \"size\": 1,\n",
    "    \"query\": {\n",
    "        \"script_score\": {\n",
    "            \"query\": {\"match_all\": {}},\n",
    "            \"script\": {\n",
    "                \"source\": \"cosineSimilarity(params.queryVector, doc['embedding']) + 1.0\",\n",
    "                \"params\": {\n",
    "                    \"queryVector\": queryVector\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = osearc.search(index=\"embeddings\", body=query, error_trace=True)\n",
    "\n",
    "# Extract hit and score\n",
    "hit = response['hits']['hits'][0]['_source']\n",
    "score = response['hits']['hits'][0]['_score']\n",
    "hit_id = response['hits']['hits'][0]['_id']\n",
    "\n",
    "print(hit_id, hit, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
