{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install opensearch-py pyspark matplotlib scikit-learn seaborn pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "rootpath = os.path.abspath(\"/home/robertc/Git/pfun-cma-model\")\n",
    "if rootpath not in sys.path:\n",
    "    sys.path.insert(0, rootpath)\n",
    "from pfun_cma_model.embed import EmbedClient, run_embedder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the embedder -> embeddings -> Opensearch domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_embedder(grid_params=dict(num=8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize opensearch client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osearc = EmbedClient(require_ssh_tunnel=False).opensearch_client\n",
    "res = osearc.search(\n",
    "    index=\"embeddings\", body={\"size\": 10, \"_source\": \"embedding\"}, scroll=\"2m\"\n",
    ")\n",
    "scroll_id = res[\"_scroll_id\"]\n",
    "scroll_size = res[\"hits\"][\"total\"][\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "# .config(\"spark.jars\", os.path.join(rootpath, \"pfun_cma_model/embed/pyspark_jars/opensearch-spark-30_2.13-1.0.1.jar\"))\n",
    "spark = SparkSession.builder \\\n",
    "    .config(\"spark.cores.max\", \"8\") \\\n",
    "    .config(\"spark.kubernetes.container.image\", \"docker.io/bitnami/spark:3.5.0-debian-11-r0\") \\\n",
    "    .config(\"spark.executor.instances\", \"4\") \\\n",
    ".config(\"spark.jars\", os.path.join(rootpath, \"pfun_cma_model/embed/pyspark_jars/elasticsearch-spark-20_2.11-8.10.2.jar\")) \\\n",
    "    .appName(\"pfun-cma-model-embed\") \\\n",
    "    .getOrCreate()\n",
    "spark.conf.set('spark.sql.shuffle.partitions', int(16 * 2.5))\n",
    "spark.conf.set('spark.default.parallelism', 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Data from OpenSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = [(d[\"_source\"][\"embedding\"][0][\"embedding\"],) for d in res[\"hits\"][\"hits\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataFromOSWithSpark(index: str = \"embeddings\", sample_fraction: float | None = 0.1):\n",
    "    #: Get data from opensearch (with spark)\n",
    "    df = (\n",
    "        spark.read.format(\"org.elasticsearch.spark.sql\")\n",
    "        .option(\"es.port\", \"9201\")\n",
    "        .option(\"es.net.ssl\", \"false\")\n",
    "        .option(\"es.nodes\", \"192.168.1.64\")\n",
    "        .load(f\"{index}/float\")\n",
    "    )\n",
    "    if sample_fraction is not None:\n",
    "        # Create random sample of 10% of the data\n",
    "        df_sample = df.sample(False, sample_fraction)\n",
    "        return df_sample\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "\n",
    "# df = getDataFromOSWithSpark(sample_fraction=0.1)\n",
    "# df.persist()\n",
    "# df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import ArrayType, DoubleType, StructType, StructField\n",
    "\n",
    "schema = StructType([StructField(\"list_features\", ArrayType(DoubleType()))])\n",
    "df = spark.createDataFrame(embeddings, schema=schema)\n",
    "\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "# UDF to convert array into vector\n",
    "vector_udf = udf(lambda l: Vectors.dense(l), VectorUDT())\n",
    "df = df.withColumn(\"features\", vector_udf(\"list_features\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(\"features\")\n",
    "df.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "kmeans = KMeans(k=8, seed=23)\n",
    "model = kmeans.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "df_pandas = pd.DataFrame(\n",
    "    model.transform(df)\n",
    "    .rdd.map(lambda r: (float(r.features[0]), float(r.features[1]), int(r.prediction)))\n",
    "    .collect(),\n",
    "    columns=[\"x\", \"y\", \"cluster\"],\n",
    ")\n",
    "df_pandas[\"x\"], df_pandas[\"y\"] = zip(*pca.fit_transform(df_pandas[[\"x\", \"y\"]]))\n",
    "plt.rc(\"figure\", figsize=(10, 8))\n",
    "sns.scatterplot(x=\"x\", y=\"y\", hue=\"cluster\", data=df_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_query_vector():\n",
    "    from pfun_cma_model.embed import encode\n",
    "    from pfun_cma_model.runtime.chalicelib.engine.cma_sleepwake import CMASleepWakeModel\n",
    "    cma = CMASleepWakeModel()\n",
    "    raw_text = cma.run().to_json()\n",
    "    queryVector = encode(raw_text)[0].tolist()\n",
    "    return queryVector\n",
    "\n",
    "\n",
    "def get_sample_query_vector():\n",
    "    sample = osearc.search(\n",
    "        index=\"embeddings\", body={\"size\": 1, \"_source\": \"embedding\"}, scroll=\"2m\"\n",
    "    )\n",
    "    queryVector = sample['hits']['hits'][0]['_source']['embedding'][0]['embedding']\n",
    "    return queryVector\n",
    "\n",
    "\n",
    "queryVector = get_sample_query_vector()\n",
    "\n",
    "query = {\n",
    "    \"size\": 1,\n",
    "    \"query\": {\n",
    "        \"script_score\": {\n",
    "            \"query\": {\"match_all\": {}},\n",
    "            \"script\": {\n",
    "                \"source\": \"cosineSimilarity(params.queryVector, doc['embedding']) + 1.0\",\n",
    "                \"params\": {\n",
    "                    \"queryVector\": queryVector\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = osearc.search(index=\"embeddings\", body=query, error_trace=True)\n",
    "\n",
    "# Extract hit and score\n",
    "hit = response['hits']['hits'][0]['_source']\n",
    "score = response['hits']['hits'][0]['_score']\n",
    "hit_id = response['hits']['hits'][0]['_id']\n",
    "\n",
    "print(hit_id, hit, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10+"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
